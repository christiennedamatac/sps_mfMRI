{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IS-RSA for networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/project/3013104.01'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/project/3013104.01/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute inter-subject representation between inter-subject network activation and intersubject SPSQ score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: dissimilarity_salience_ventral_attention.csv\n",
      "Complete: dissimilarity_salience_ventral_attention_isrsa.csv\n",
      "Processing: dissimilarity_control.csv\n",
      "Complete: dissimilarity_control_isrsa.csv\n",
      "Processing: dissimilarity_default.csv\n",
      "Complete: dissimilarity_default_isrsa.csv\n",
      "Concatenated SPSQ_pos in neutral\n",
      "Processing: dissimilarity_salience_ventral_attention.csv\n",
      "Complete: dissimilarity_salience_ventral_attention_isrsa.csv\n",
      "Processing: dissimilarity_control.csv\n",
      "Complete: dissimilarity_control_isrsa.csv\n",
      "Processing: dissimilarity_default.csv\n",
      "Complete: dissimilarity_default_isrsa.csv\n",
      "Concatenated SPSQ_neg in neutral\n",
      "Processing: dissimilarity_salience_ventral_attention.csv\n",
      "Complete: dissimilarity_salience_ventral_attention_isrsa.csv\n",
      "Processing: dissimilarity_control.csv\n",
      "Complete: dissimilarity_control_isrsa.csv\n",
      "Processing: dissimilarity_default.csv\n",
      "Complete: dissimilarity_default_isrsa.csv\n",
      "Concatenated SPSQ_pos in threat\n",
      "Processing: dissimilarity_salience_ventral_attention.csv\n",
      "Complete: dissimilarity_salience_ventral_attention_isrsa.csv\n",
      "Processing: dissimilarity_control.csv\n",
      "Complete: dissimilarity_control_isrsa.csv\n",
      "Processing: dissimilarity_default.csv\n",
      "Complete: dissimilarity_default_isrsa.csv\n",
      "Concatenated SPSQ_neg in threat\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "from itertools import permutations\n",
    "import datetime\n",
    "import glob\n",
    "\n",
    "# Function to create permuted distance matrices\n",
    "def create_permuted_distance_matrices(original_distance_matrix, n_permutations):\n",
    "    num_subjects = original_distance_matrix.shape[0]\n",
    "    permuted_distance_matrices = []\n",
    "    \n",
    "    for _ in range(n_permutations):\n",
    "        # Create a random permutation of the questionnaire scores\n",
    "        permutation_indices = np.random.permutation(num_subjects)\n",
    "\n",
    "        # Reconstruct the permuted distance matrix while preserving subject order\n",
    "        permuted_matrix = original_distance_matrix[permutation_indices][:, permutation_indices]\n",
    "        \n",
    "        permuted_distance_matrices.append(permuted_matrix)\n",
    "    \n",
    "    return permuted_distance_matrices\n",
    "\n",
    "# Function to concatenate CSV files\n",
    "def concatenate_csv_files(frame, dimension, formatted_date):\n",
    "    isrsa_dir = f'analysis/inter-subject_representational_similarity_analysis/{frame}_{formatted_date}_networks_{model}/{dimension}'\n",
    "    out_dir = isrsa_dir\n",
    "\n",
    "    concatenated_dataframes = []\n",
    "\n",
    "    for csv_file in glob.glob(os.path.join(isrsa_dir, '*.csv')):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        concatenated_dataframes.append(df)\n",
    "\n",
    "    concatenated_dataframe = pd.concat(concatenated_dataframes, ignore_index=True)\n",
    "\n",
    "    output_filename = os.path.join(out_dir, f'{dimension}_isrsa_concat.csv')\n",
    "    concatenated_dataframe.to_csv(output_filename, index=False)\n",
    "\n",
    "    print(f\"Concatenated {dimension} in {frame}\")\n",
    "\n",
    "                          \n",
    "aural_framings = ['neutral', 'threat']\n",
    "models = ['euclidean_distance']\n",
    "dimensions = ['SPSQ_pos', 'SPSQ_neg'] \n",
    "\n",
    "# Today's date\n",
    "today = datetime.date.today()\n",
    "formatted_date = today.strftime('%d-%m-%Y')\n",
    "\n",
    "for frame in aural_framings:\n",
    "    for model in models:\n",
    "        for dimension in dimensions:\n",
    "\n",
    "            fmri_similarity_dir = f'analysis/inter-subject_matrices_fmri/network/dissimilarity_matrices_mfmri_network_{frame}'\n",
    "            output_dir = f'analysis/inter-subject_representational_similarity_analysis/{frame}_{formatted_date}_networks_{model}/{dimension}'\n",
    "\n",
    "            # Delete output_dir if it exists\n",
    "            if os.path.exists(output_dir):\n",
    "                for file in os.listdir(output_dir):\n",
    "                    file_path = os.path.join(output_dir, file)\n",
    "                    try:\n",
    "                        if os.path.isfile(file_path):\n",
    "                            os.unlink(file_path)\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                os.rmdir(output_dir)\n",
    "\n",
    "            # Create output_dir\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            # List all brain network (dis)similarity files in fmri_similarity_dir\n",
    "            brain_matrices = [f for f in os.listdir(fmri_similarity_dir) if f.endswith('.csv')]\n",
    "\n",
    "            # Questionnaire distance/dissimilarity matrix \n",
    "            questionnaire_matrix_path = f'analysis/inter-subject_matrices_spsq/{model}_composite/{model}_matrix_{dimension}.csv'\n",
    "            questionnaire_matrix = pd.read_csv(questionnaire_matrix_path, header=0, index_col=0).values\n",
    "            questionnaire_vector = questionnaire_matrix[np.tril_indices(questionnaire_matrix.shape[0])]\n",
    "\n",
    "            # How many permutations?\n",
    "            n_permutations = 10000\n",
    "\n",
    "            # Create a list of permuted distance matrices to use for all brain matrices\n",
    "            permuted_distance_matrices = create_permuted_distance_matrices(questionnaire_matrix, n_permutations)\n",
    "\n",
    "            # Loop through each brain node similarity file\n",
    "            for brain_matrix_file in brain_matrices:\n",
    "                print(f\"Processing: {brain_matrix_file}\")\n",
    "\n",
    "                brain_matrix = pd.read_csv(os.path.join(fmri_similarity_dir, brain_matrix_file), header=None, index_col=None).values\n",
    "                brain_vector = brain_matrix[np.tril_indices(brain_matrix.shape[0])]\n",
    "\n",
    "                # Spearman correlation between vectorized lower triangles of brain and questionnaire matrices\n",
    "                correlation, p_value = spearmanr(brain_vector, questionnaire_vector, nan_policy='omit')\n",
    "\n",
    "                # Permutations using the pre-generated list of permuted distance matrices\n",
    "                correlation_permuted = []\n",
    "                for permuted_matrix in permuted_distance_matrices:\n",
    "                    permuted_questionnaire_vector = permuted_matrix[np.tril_indices(permuted_matrix.shape[0])]\n",
    "                    corr, _ = spearmanr(brain_vector, permuted_questionnaire_vector, nan_policy='omit')\n",
    "                    correlation_permuted.append(corr)\n",
    "\n",
    "                p_value_corrected = (np.sum(np.abs(correlation_permuted) >= np.abs(correlation)) + 1) / (n_permutations + 1)\n",
    "\n",
    "                # Dataframe to store results\n",
    "                result_df = pd.DataFrame({\n",
    "                    'network_similarity_matrix': [brain_matrix_file],\n",
    "                    'spearman_r': [correlation],\n",
    "                    'p_uncorrected': [p_value],\n",
    "                    'p_permuted': [p_value_corrected]\n",
    "                })\n",
    "\n",
    "                # Save in output_dir\n",
    "                output_file = os.path.splitext(brain_matrix_file)[0] + '_isrsa.csv'\n",
    "                result_df.to_csv(os.path.join(output_dir, output_file), index=False)\n",
    "\n",
    "                print(f\"Complete: {output_file}\")\n",
    "\n",
    "            # Call the function to concatenate CSV files\n",
    "            concatenate_csv_files(frame, dimension, formatted_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate for each model of SPS (dis)similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "framing = ['neutral', 'threat']\n",
    "models = ['euclidean_distance']\n",
    "dimensions = ['SPSQ_pos', 'SPSQ_neg']\n",
    "\n",
    "for model in models:\n",
    "    # Initialize an empty list to store DataFrames\n",
    "    data_frames = []\n",
    "    \n",
    "    for frame in framing:\n",
    "        for dim in dimensions:\n",
    "            working_dir = f'analysis/inter-subject_representational_similarity_analysis/{frame}_03-01-2024_networks_{model}/{dim}'\n",
    "            file_path = f'{working_dir}/{dim}_isrsa_concat.csv'\n",
    "            \n",
    "            # Check if the file exists before reading it\n",
    "            if os.path.exists(file_path):\n",
    "                data = pd.read_csv(file_path)\n",
    "                # Add \"framing\" and \"dimension\" columns\n",
    "                data['framing'] = frame\n",
    "                data['dimension'] = dim\n",
    "                data_frames.append(data)\n",
    "\n",
    "    # Concatenate the list of DataFrames into one DataFrame\n",
    "    concatenated_data = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "    # Save the concatenated data to the out_file\n",
    "    out_file = f'analysis/inter-subject_representational_similarity_analysis/{model}_results_concat.csv'\n",
    "    concatenated_data.to_csv(out_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FDR correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FDR correction completed and saved to analysis/inter-subject_representational_similarity_analysis/euclidean_distance_results_concat_subset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "# Load your CSV file into a DataFrame\n",
    "file_path = \"analysis/inter-subject_representational_similarity_analysis/euclidean_distance_results_concat.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Perform FDR correction\n",
    "pvals_corrected = fdrcorrection(df['p_permuted'])[1]\n",
    "\n",
    "# Create a new column in the DataFrame for the corrected p-values\n",
    "df['p_fdr'] = pvals_corrected\n",
    "\n",
    "# Save the updated DataFrame back to a CSV file\n",
    "output_file = \"analysis/inter-subject_representational_similarity_analysis/euclidean_distance_results_concat_subset.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"FDR correction completed and saved to\", output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot IS-RSA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "# Load data from CSV file\n",
    "file_path = 'analysis/inter-subject_representational_similarity_analysis/euclidean_distance_results_concat_subset.csv'\n",
    "df = pd.read_csv(file_path, header=0, index_col=None)\n",
    "\n",
    "# Sort data by 'SPSQ dimension', 'functional network', and 'aural framing'\n",
    "df.sort_values(by=['SPSQ dimension', 'functional network', 'aural framing'], inplace=True)\n",
    "\n",
    "# Separate data by network and aural framing\n",
    "networks = sorted(set(df['functional network']))\n",
    "aural_framings = sorted(set(df['aural framing']))\n",
    "dimensions = sorted(set(df['SPSQ dimension']))\n",
    "\n",
    "# Define colors for each network\n",
    "network_colors = {'control': '#DA963F', 'default': '#BC4751', 'salience': '#B345EE'}\n",
    "\n",
    "# Set font size\n",
    "font_size = 26\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(len(dimensions), 1, figsize=(8, 11), sharex=True, gridspec_kw={'hspace': 0.4})\n",
    "\n",
    "# Initialize variables to store maximum and minimum y-axis values\n",
    "max_y = float('-inf')\n",
    "min_y = float('inf')\n",
    "\n",
    "for i, dimension in enumerate(dimensions):\n",
    "    ax = axs[i]\n",
    "\n",
    "    tick_labels = []  # List to store tick labels\n",
    "    tick_positions = []  # List to store tick positions\n",
    "    \n",
    "    for j, network in enumerate(networks):\n",
    "        bars = []  # List to store bar objects for legend\n",
    "        for k, framing in enumerate(aural_framings):\n",
    "            # Filter data for the current SPSQ dimension, network, and aural framing\n",
    "            subset = df[(df['SPSQ dimension'] == dimension) & (df['functional network'] == network) & (df['aural framing'] == framing)]\n",
    "\n",
    "            # Extract values\n",
    "            rs = subset['Spearman r'].values\n",
    "            positions = np.arange(len(rs)) + (k + j * len(aural_framings)) * 0.4  # Adjust the spacing (0.4) as needed\n",
    "\n",
    "            tick_positions.extend(positions)  # Add positions to the list\n",
    "            tick_labels.extend([f'{network} - {framing}' for _ in positions])  # Add labels to the list\n",
    "\n",
    "            # Update maximum and minimum y-axis values\n",
    "            max_y = max(max_y, np.max(rs))\n",
    "            min_y = min(min_y, np.min(rs))\n",
    "\n",
    "            # Define hatch pattern based on 'aural framing'\n",
    "            hatch = None\n",
    "            if framing == 'threat':\n",
    "                hatch = '////'  # Pattern for 'threat' framing\n",
    "\n",
    "            # Plotting bars with network-specific color and label for aural framing\n",
    "            bar = ax.bar(positions, rs, label=f'{network} - {framing}', width=0.35, \n",
    "                         color=network_colors[network], edgecolor='black', linewidth=1, alpha=0.9, hatch=hatch)\n",
    "            bars.extend(bar)\n",
    "\n",
    "    ax.set_title(f'SPSQ-SF {dimension} dimension', fontsize=font_size)\n",
    "\n",
    "    # Set y-axis label for the first subplot\n",
    "    #if i == 0 and dimension != 'positive':\n",
    "        #set_ylabel('IS-RSA Spearman r', fontsize=font_size)\n",
    "\n",
    "# Set y-axis limits for all subplots\n",
    "for ax in axs:\n",
    "    ax.set_ylim(0, .2)\n",
    "\n",
    "# Replace specific strings in the x-axis tick labels\n",
    "tick_labels = [label.replace('control -', 'CEN').replace('default -', 'DMN').replace('salience -', 'SN') for label in tick_labels]\n",
    "\n",
    "# Set x-axis tick positions and labels for the bottom subplot\n",
    "axs[-1].set_xticks(tick_positions)\n",
    "axs[-1].set_xticklabels(tick_labels, rotation=45, ha='right')\n",
    "axs[-1].set_xlabel('network and condition', fontsize=font_size)\n",
    "\n",
    "# Remove legend for the negative dimension plot\n",
    "axs[0].legend().set_visible(False)\n",
    "\n",
    "# Remove box around plots\n",
    "for ax in axs:\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Increase tick font size\n",
    "for ax in axs:\n",
    "    ax.tick_params(axis='both', which='major', labelsize=font_size)\n",
    "\n",
    "# Add a single y-axis label spanning the length of both plots\n",
    "fig.text(0.05, 0.63, 'IS-RSA Spearman r\\n(neural dissimilarity ~ SPSQ-SF distance)', \n",
    "         va='center', rotation='vertical', fontsize=font_size, ha='center')\n",
    "\n",
    "# Adjust the figure boundaries to ensure the y-axis title is fully visible\n",
    "plt.subplots_adjust(left=0.25, right=0.95, top=0.95, bottom=0.4)\n",
    "\n",
    "# Save the entire figure as an A4 portrait PDF\n",
    "pdf_path = 'analysis/plots/isrsa_network_spearman_r_bars.pdf'\n",
    "plt.savefig(pdf_path, format='pdf')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
